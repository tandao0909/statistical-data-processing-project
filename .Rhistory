# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "LDA")
conf_matrix <- table(test_data$diabetes_012, undersampling_results$qda_predictions)
conf_matrix
eval_multi_class(conf_matrix)
# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "QDA")
smote_data <- read.csv("data/smote_augmented_data_80_percent.csv")
smote_data <- smote_data |> mutate(across(everything(), as.factor))
glimpse(smote_data)
table(smote_data$diabetes_012)
smote_results <- evaluate_models(smote_data, test_data)
conf_matrix <- table(test_data$diabetes_012, smote_results$lda_predictions)
conf_matrix
eval_multi_class(conf_matrix)
# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "LDA")
conf_matrix <- table(test_data$diabetes_012, smote_results$qda_predictions)
conf_matrix
eval_multi_class(conf_matrix)
# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "QDA")
convert_to_binary <- function(data) {
data |> mutate(diabetes_012 = ifelse(diabetes_012 %in% c(1, 2), 1, ifelse(diabetes_012 == 0, 0, diabetes_012)))
}
binary_train_data <- convert_to_binary(train_data)
binary_oversampling_data <- convert_to_binary(oversampling_data)
binary_undersampling_data <- convert_to_binary(undersampling_data)
binary_smote_data <- convert_to_binary(smote_data)
binary_test_data <- convert_to_binary(test_data)
table(binary_train_data$diabetes_012)
table(binary_test_data$diabetes_012)
binary_results <- evaluate_models(binary_train_data, binary_test_data)
conf_matrix <- table(binary_test_data$diabetes_012, binary_results$lda_predictions)
conf_matrix
eval_multi_class(conf_matrix)
# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "LDA")
conf_matrix <- table(binary_test_data$diabetes_012, binary_results$qda_predictions)
conf_matrix
eval_multi_class(conf_matrix)
# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "QDA")
oversampling_results_binary <- evaluate_models(binary_oversampling_data, binary_test_data)
conf_matrix <- table(binary_test_data$diabetes_012, oversampling_results_binary$lda_predictions)
conf_matrix
eval_multi_class(conf_matrix)
# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "LDA")
conf_matrix <- table(binary_test_data$diabetes_012, oversampling_results_binary$qda_predictions)
conf_matrix
eval_multi_class(conf_matrix)
# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "QDA")
undersampling_results_binary <- evaluate_models(binary_undersampling_data, binary_test_data)
conf_matrix <- table(binary_test_data$diabetes_012, undersampling_results_binary$lda_predictions)
conf_matrix
eval_multi_class(conf_matrix)
# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "LDA")
conf_matrix <- table(binary_test_data$diabetes_012, undersampling_results_binary$qda_predictions)
conf_matrix
eval_multi_class(conf_matrix)
# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "QDA")
smote_results_binary <- evaluate_models(binary_undersampling_data, binary_test_data)
conf_matrix <- table(binary_test_data$diabetes_012, smote_results_binary$lda_predictions)
conf_matrix
eval_multi_class(conf_matrix)
# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "LDA")
conf_matrix <- table(binary_test_data$diabetes_012, smote_results_binary$qda_predictions)
conf_matrix
eval_multi_class(conf_matrix)
# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "QDA")
convert_to_binary <- function(data) {
data |> mutate(diabetes_012 = ifelse(diabetes_012 %in% c(0, 2), 1, ifelse(diabetes_012 == 1, 0, diabetes_012)))
}
binary_train_data <- convert_to_binary(train_data)
binary_oversampling_data <- convert_to_binary(oversampling_data)
binary_undersampling_data <- convert_to_binary(undersampling_data)
binary_smote_data <- convert_to_binary(smote_data)
binary_test_data <- convert_to_binary(test_data)
table(binary_train_data$diabetes_012)
table(binary_test_data$diabetes_012)
binary_results <- evaluate_models(binary_train_data, binary_test_data)
conf_matrix <- table(binary_test_data$diabetes_012, binary_results$lda_predictions)
conf_matrix
eval_multi_class(conf_matrix)
# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "LDA")
conf_matrix <- table(binary_test_data$diabetes_012, binary_results$qda_predictions)
conf_matrix
eval_multi_class(conf_matrix)
# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "QDA")
oversampling_results_binary <- evaluate_models(binary_oversampling_data, binary_test_data)
conf_matrix <- table(binary_test_data$diabetes_012, oversampling_results_binary$lda_predictions)
conf_matrix
eval_multi_class(conf_matrix)
# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "LDA")
conf_matrix <- table(binary_test_data$diabetes_012, oversampling_results_binary$qda_predictions)
conf_matrix
eval_multi_class(conf_matrix)
# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "QDA")
undersampling_results_binary <- evaluate_models(binary_undersampling_data, binary_test_data)
smote_results_binary <- evaluate_models(binary_undersampling_data, binary_test_data)
train_without_cross <- function(train_data, test_data) {
# Train LDA model on train_data
lda_model <- lda(diabetes_012 ~ ., data = train_data)
# Predict on train_data
lda_predictions_train <- predict(lda_model, train_data)$class
lda_pred_probs_train <- predict(lda_model, train_data)$posterior
# Calculate confusion matrix and metrics for training data
lda_conf_matrix_train <- table(train_data$diabetes_012, lda_predictions_train)
lda_metrics_train <- eval_multi_class(lda_conf_matrix_train)
# Print metrics for training data
cat("LDA Training Metrics:\n")
print(lda_metrics_train)
# Predict on test_data
lda_predictions <- predict(lda_model, test_data)$class
lda_pred_probs <- predict(lda_model, test_data)$posterior
# Train QDA model on train_data
qda_model <- qda(diabetes_012 ~ ., data = train_data)
# Predict on train_data
qda_predictions_train <- predict(qda_model, train_data)$class
qda_pred_probs_train <- predict(qda_model, train_data)$posterior
# Calculate confusion matrix and metrics for training data
qda_conf_matrix_train <- table(train_data$diabetes_012, qda_predictions_train)
qda_metrics_train <- eval_multi_class(qda_conf_matrix_train)
# Print metrics for training data
cat("QDA Training Metrics:\n")
print(qda_metrics_train)
# Predict on test_data
qda_predictions <- predict(qda_model, test_data)$class
qda_pred_probs <- predict(qda_model, test_data)$posterior
# Return predictions and probabilities for both models
return(list(
lda_predictions = lda_predictions,
lda_pred_probs = lda_pred_probs,
qda_predictions = qda_predictions,
qda_pred_probs = qda_pred_probs
))
}
train_without_cross(undersampling_data, test_data)
undersampling_results <- train_without_cross(undersampling_data, test_data)
undersampling_results_binary <- train_without_cross(binary_undersampling_data, binary_test_data)
conf_matrix <- table(binary_test_data$diabetes_012, undersampling_results_binary$lda_predictions)
conf_matrix
eval_multi_class(conf_matrix)
# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "LDA")
conf_matrix <- table(binary_test_data$diabetes_012, undersampling_results_binary$qda_predictions)
conf_matrix
eval_multi_class(conf_matrix)
# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "QDA")
smote_results_binary <- evaluate_models(binary_smote_data, binary_test_data)
conf_matrix <- table(binary_test_data$diabetes_012, smote_results_binary$lda_predictions)
conf_matrix
eval_multi_class(conf_matrix)
# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "LDA")
conf_matrix <- table(binary_test_data$diabetes_012, smote_results_binary$qda_predictions)
conf_matrix
eval_multi_class(conf_matrix)
# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "QDA")
convert_to_binary <- function(data) {
data |> mutate(diabetes_012 = ifelse(diabetes_012 %in% c(0, 1), 0, ifelse(diabetes_012 == 2, 1, diabetes_012)))
}
binary_train_data <- convert_to_binary(train_data)
binary_oversampling_data <- convert_to_binary(oversampling_data)
binary_undersampling_data <- convert_to_binary(undersampling_data)
binary_smote_data <- convert_to_binary(smote_data)
binary_test_data <- convert_to_binary(test_data)
table(binary_train_data$diabetes_012)
table(binary_test_data$diabetes_012)
binary_results <- evaluate_models(binary_train_data, binary_test_data)
conf_matrix <- table(binary_test_data$diabetes_012, binary_results$lda_predictions)
conf_matrix
eval_multi_class(conf_matrix)
# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "LDA")
conf_matrix <- table(binary_test_data$diabetes_012, binary_results$qda_predictions)
conf_matrix
eval_multi_class(conf_matrix)
# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "QDA")
oversampling_results_binary <- evaluate_models(binary_oversampling_data, binary_test_data)
conf_matrix <- table(binary_test_data$diabetes_012, oversampling_results_binary$lda_predictions)
conf_matrix
eval_multi_class(conf_matrix)
# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "LDA")
conf_matrix <- table(binary_test_data$diabetes_012, oversampling_results_binary$qda_predictions)
conf_matrix
eval_multi_class(conf_matrix)
# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "QDA")
undersampling_results_binary <- evaluate_models(binary_undersampling_data, binary_test_data)
conf_matrix <- table(binary_test_data$diabetes_012, undersampling_results_binary$lda_predictions)
conf_matrix
eval_multi_class(conf_matrix)
# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "LDA")
conf_matrix <- table(binary_test_data$diabetes_012, undersampling_results_binary$qda_predictions)
conf_matrix
eval_multi_class(conf_matrix)
# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "QDA")
smote_results_binary <- evaluate_models(binary_undersampling_data, binary_test_data)
conf_matrix <- table(binary_test_data$diabetes_012, smote_results_binary$lda_predictions)
conf_matrix
eval_multi_class(conf_matrix)
# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "LDA")
conf_matrix <- table(binary_test_data$diabetes_012, smote_results_binary$qda_predictions)
conf_matrix
eval_multi_class(conf_matrix)
# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "QDA")
library(ggplot2)
library(tidyverse)
library(MASS)
library(janitor)
library(dplyr)
library(pROC)
library(irr)
library(reshape2)
library(caret)
# Useful function: Cross-validation for LDA and QDA
cross_validate <- function(model_formula, data, k = 5, method = "lda") {
set.seed(123) # Set seed for reproducibility
# Create k-folds
folds <- sample(rep(1:k, length.out = nrow(data)))
# Initialize a list to store results and models
results <- list()
models <- list()
# Perform cross-validation
for (i in 1:k) {
# Split data into training and testing sets
train_data <- data[folds != i, ]
test_data <- data[folds == i, ]
# Train the model
model <- if (method == "lda") {
lda(formula = model_formula, data = train_data)
} else if (method == "qda") {
qda(formula = model_formula, data = train_data)
} else {
stop("Unsupported method. Use 'lda' or 'qda'.")
}
# Predict on the testing set
predictions <- predict(model, test_data)$class
# Calculate metrics
confusion <- table(predictions, test_data$diabetes_012)
accuracy <- sum(diag(confusion)) / sum(confusion)
precision <- diag(confusion) / rowSums(confusion)
precision[is.na(precision)] <- 0
recall <- diag(confusion) / colSums(confusion)
recall[is.na(recall)] <- 0
f1 <- 2 * (precision * recall) / (precision + recall)
f1[is.na(f1)] <- 0
# Calculate kappa
confusion_df <- as.data.frame(as.table(confusion))
kappa <- kappam.fleiss(confusion_df)$value
# Store the result and model
results[[i]] <- list(
accuracy = accuracy,
precision = precision,
recall = recall,
f1 = f1,
kappa = kappa
)
models[[i]] <- model
}
return(list(models = models, results = results))
}
# Multi-class evaluation
eval_multi_class <- function(conf_matrix) {
cc <- sum(diag(conf_matrix))
sc <- sum(conf_matrix)
pp <- colSums(conf_matrix)
tt <- rowSums(conf_matrix)
prec <- diag(conf_matrix) / pp
prec[is.na(prec)] <- 0
recall <- diag(conf_matrix) / tt
recall[is.na(recall)] <- 0
macro_prec <- mean(prec, na.rm = TRUE)
macro_recall <- mean(recall, na.rm = TRUE)
macro_f1 <- 2 * macro_prec * macro_recall / (macro_prec + macro_recall)
acc <- cc / sc
kap <- (cc * sc - sum(pp * tt)) / (sc^2 - sum(pp * tt))
return(list(Precision = prec, Recall = recall, Accuracy = acc, Kappa = kap, Macro_F1 = macro_f1))
}
# Evaluate models with enhanced flexibility
evaluate_models <- function(train_data, test_data) {
# LDA cross-validation
lda_results <- cross_validate(diabetes_012 ~ ., train_data, method = "lda")
lda_avg_results <- sapply(lda_results$results, function(res) sapply(res, mean))
# QDA cross-validation
qda_results <- cross_validate(diabetes_012 ~ ., train_data, method = "qda")
qda_avg_results <- sapply(qda_results$results, function(res) sapply(res, mean))
# Determine the best model based on F1 score
best_model <- ifelse(mean(lda_avg_results["f1", ]) > mean(qda_avg_results["f1", ]), "LDA", "QDA")
# Train final models
final_lda_model <- lda(diabetes_012 ~ ., data = train_data)
final_qda_model <- qda(diabetes_012 ~ ., data = train_data)
# Predict on test data
lda_predictions <- predict(final_lda_model, test_data)$class
qda_predictions <- predict(final_qda_model, test_data)$class
# Create confusion matrices
lda_confusion <- table(test_data$diabetes_012, lda_predictions)
qda_confusion <- table(test_data$diabetes_012, qda_predictions)
# Evaluate metrics
lda_metrics <- eval_multi_class(lda_confusion)
qda_metrics <- eval_multi_class(qda_confusion)
# Compile results
results <- data.frame(
Metric = c("Accuracy", "Precision", "Recall", "F1", "Kappa"),
LDA = c(lda_metrics$Accuracy, mean(lda_metrics$Precision, na.rm = TRUE), mean(lda_metrics$Recall, na.rm = TRUE), lda_metrics$Macro_F1, lda_metrics$Kappa),
QDA = c(qda_metrics$Accuracy, mean(qda_metrics$Precision, na.rm = TRUE), mean(qda_metrics$Recall, na.rm = TRUE), qda_metrics$Macro_F1, qda_metrics$Kappa)
)
# Visualize results
metrics_data <- melt(results, id.vars = "Metric")
ggplot(metrics_data, aes(x = Metric, y = value, fill = variable)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Performance Metrics for LDA and QDA Models",
x = "Metric",
y = "Value") +
theme_minimal()
return(list(results = results, lda_predictions = lda_predictions, qda_predictions = qda_predictions))
}
smote_results_binary <- evaluate_models(binary_smote_data, binary_test_data)
conf_matrix <- table(binary_test_data$diabetes_012, smote_results_binary$lda_predictions)
conf_matrix
eval_multi_class(conf_matrix)
# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "LDA")
library(ggplot2)
library(tidyverse)
library(MASS)
library(janitor)
library(dplyr)
library(pROC)
cleaned_data <- read.csv(file = "data/cleaned_data.csv")
glimpse(cleaned_data|>clean_names())
process_data <- function(data) {
# Clean column names
data <- clean_names(data)
# Hàm để phân loại BMI
categorize_bmi <- function(bmi) {
if (bmi < 18.5) {
return(0) # Underweight
} else if (bmi >= 18.5 & bmi < 24.9) {
return(1) # Normal weight
} else if (bmi >= 25 & bmi < 29.9) {
return(2) # Overweight
} else if (bmi >= 30 & bmi < 34.9) {
return(3) # Obesity class 1
} else if (bmi >= 35 & bmi < 39.9) {
return(4) # Obesity class 2
} else {
return(5) # Obesity class 3
}
}
categorize_phys <- function(phys) {
if (phys == 0) {
return(0) # 0 day
} else if (phys <= 7) {
return(1) # few days
} else if (phys <= 30) {
return(2) # many days
}
}
# Tạo cột mới bmi_category và phys_category cho dataframe data
data$bmi_category <- sapply(data$bmi, categorize_bmi)
data$phys_category <- sapply(data$phys_hlth, categorize_phys)
# Xóa các cột không cần thiết
data <- within(data, rm("bmi", "ment_hlth", "phys_hlth"))
data <- data |> mutate(across(everything(), as.factor))
return(data)
}
cleaned_data <- process_data(cleaned_data)
glimpse(cleaned_data)
# Hàm để chia train test theo tỷ lệ
train_test_split <- function(data, train_ratio = 0.8) {
set.seed(123)  # Đặt seed để đảm bảo tính tái lập
# Randomly shuffle the data
shuffled_indices <- sample(seq_len(nrow(data)))
# Determine the number of training samples
train_size <- floor(train_ratio * nrow(data))
# Split the data into training and testing sets
train_indices <- shuffled_indices[1:train_size]
test_indices <- shuffled_indices[(train_size + 1):nrow(data)]
train_data <- data[train_indices, ]
test_data <- data[test_indices, ]
res <- list(
train_data = train_data,
test_data = test_data
)
return(res)
}
split_cleaned_data <- train_test_split(cleaned_data)
print(table(split_cleaned_data$train_data$diabetes_012))
print(table(split_cleaned_data$test_data$diabetes_012))
write.csv(split_cleaned_data$train_data, file = "data/train_data.csv", row.names = FALSE)
write.csv(split_cleaned_data$test_data, file = "data/test_data.csv", row.names = FALSE)
if (!require("reticulate")) install.packages("reticulate")
if (!require("tidyverse")) install.packages("tidyverse")
if (!require("smotefamily")) install.packages("smotefamily")
library(reticulate)
library(tidyverse)
library(smotefamily)
file_path <- file.path("data/train_data.csv")
data <- read.csv(file_path)
data
# kiểm tra data imbalance
target_distribution <- table(data$diabetes_012)
print(target_distribution)
imbalance_ratio <- target_distribution["0"] / target_distribution["1"]
cat("Imbalance Ratio:", imbalance_ratio, "\n")
resample_data <- function(df, n, replace = FALSE) {
df[sample(nrow(df), n, replace = replace), ]
}
# cột chứa nhãn (target) và các đặc trưng (features)
target_column <- "diabetes_012"
X <- data[, !names(data) %in% c(target_column)]
y <- data[[target_column]]
# 1. Undersampling
min_class_count <- min(table(y))
undersampled_data <- data.frame()
for (label in unique(y)) {
subset <- data[data[[target_column]] == label, ]
undersampled_subset <- resample_data(subset, min_class_count)
undersampled_data <- rbind(undersampled_data, undersampled_subset)
}
write.csv(undersampled_data, "undersampled_data.csv", row.names = FALSE)
cat("\nĐã lưu dữ liệu undersampled vào 'undersampled_data.csv'\n")
# 2. Oversampling (tăng 2 nhãn ít lên bằng 80% lượng nhãn nhiều nhất)
max_class_count <- max(table(y))
oversample_limit <- as.integer(max_class_count * 0.8)
oversampled_data <- data.frame()
for (label in unique(y)) {
subset <- data[data[[target_column]] == label, ]
if (nrow(subset) < oversample_limit) {
oversampled_subset <- resample_data(subset, oversample_limit, replace = TRUE)
} else {
oversampled_subset <- subset
}
oversampled_data <- rbind(oversampled_data, oversampled_subset)
}
write.csv(oversampled_data, "oversampled_data.csv", row.names = FALSE)
cat("\nĐã lưu dữ liệu oversampled vào 'oversampled_data.csv'\n")
library(caret)
library(dplyr)
# Tính số lượng mẫu cần tăng cường
majority_count <- sum(data$diabetes_012 == 0)
augmentation_target <- round(majority_count * 0.8)
# Tách dữ liệu gốc theo từng nhãn
data_0 <- data[data$diabetes_012 == 0, ]
data_1 <- data[data$diabetes_012 == 1, ]
data_2 <- data[data$diabetes_012 == 2, ]
# One-hot encoding cho dữ liệu nhãn 1 và 2
categorical_columns <- setdiff(names(data), "diabetes_012")
one_hot_encoded <- dummyVars(~ ., data = data[, categorical_columns])
X_encoded <- predict(one_hot_encoded, newdata = data[, categorical_columns])
X_encoded <- as.data.frame(X_encoded)
X_1 <- X_encoded[data$diabetes_012 == 1, ]
X_2 <- X_encoded[data$diabetes_012 == 2, ]
X_0 <- X_encoded[data$diabetes_012 == 0, ]
# Gán nhãn mục tiêu
y_1 <- as.factor(data_1$diabetes_012)
y_2 <- as.factor(data_2$diabetes_012)
# Tính số mẫu cần bổ sung cho mỗi nhãn
required_1 <- augmentation_target - nrow(data_1)
required_2 <- augmentation_target - nrow(data_2)
# Áp dụng SMOTE cho nhãn 1
smote_1 <- SMOTE(X_1, y_1, K = 5, dup_size = ceiling(required_1 / nrow(X_1)))
# Áp dụng SMOTE cho nhãn 2
smote_2 <- SMOTE(X_2, y_2, K = 5, dup_size = ceiling(required_2 / nrow(X_2)))
# Lấy dữ liệu đã tăng cường
X_1_smote <- round(smote_1$data[, -ncol(smote_1$data)])
y_1_smote <- smote_1$data[[ncol(smote_1$data)]]
X_2_smote <- round(smote_2$data[, -ncol(smote_2$data)])
y_2_smote <- smote_2$data[[ncol(smote_2$data)]]
# Kết hợp lại dữ liệu
X_combined <- rbind(X_0, X_1_smote, X_2_smote)
y_combined <- c(rep(0, nrow(X_0)), as.numeric(y_1_smote), as.numeric(y_2_smote))
final_data <- cbind(X_combined, diabetes_012 = y_combined)
write.csv(final_data, "balanced_data_80_percent.csv", row.names = FALSE)
cat("\nDữ liệu đã lưu vào file 'balanced_data_80_percent.csv'")
cat("\nPhân phối nhãn sau SMOTE:\n")
print(table(y_combined))
# Phân phối sau khi tăng cường
library(ggplot2)
ggplot(final_data, aes(x = factor(diabetes_012))) +
geom_bar(fill = "steelblue") +
labs(title = paste("Bar Chart of", target_column),
x = target_column,
y = "Count") +
theme_minimal() +
theme(text = element_text(size = 12))
knitr::opts_chunk$set(echo = TRUE)
data <- read.csv("/data/diabetes_012_health_indicators_BRFSS2015.csv", na=c("", "NA", "N/A")) |> clean_names()
data <- read.csv("data/diabetes_012_health_indicators_BRFSS2015.csv", na=c("", "NA", "N/A")) |> clean_names()
glimpse(data)
train_data <- read.csv("data/train_data.csv")
test_data <- read.csv("data/test_data.csv")
