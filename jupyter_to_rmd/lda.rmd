
```{r}
library(ggplot2)
library(tidyverse)
library(MASS)
library(janitor)
library(dplyr)
library(pROC)
library(irr)
library(reshape2)
library(caret)

# Useful function
# Cross validation LDA
# Cross validation LDA
lda_cross_validate <- function(model_formula, data, k = 5) {
    set.seed(123) # Set seed for reproducibility
    
    # Create k-folds
    folds <- sample(rep(1:k, length.out = nrow(data)))
    
    # Initialize a list to store results and models
    results <- list()
    models <- list()
    
    # Perform cross-validation
    for (i in 1:k) {
        # Split data into training and testing sets
        train_data <- data[folds != i, ]
        test_data <- data[folds == i, ]
        
        # Train the model on the training set
        model <- lda(formula = model_formula, data = train_data)
        
        # Predict on the testing set
        predictions <- predict(model, test_data)$class
        
        # Calculate metrics
        confusion <- table(predictions, test_data$diabetes_012)
        accuracy <- sum(diag(confusion)) / sum(confusion)
        precision <- diag(confusion) / rowSums(confusion)
        precision[is.nan(precision)] <- 0
        recall <- diag(confusion) / colSums(confusion)
        recall[is.nan(recall)] <- 0
        f1 <- 2 * (precision * recall) / (precision + recall)
        f1[is.nan(f1)] <- 0
        
        # Convert confusion matrix to data frame for kappam.fleiss
        confusion_df <- as.data.frame(as.table(confusion))
        kappa <- kappam.fleiss(confusion_df)$value
        
        # Store the result and model
        results[[i]] <- list(
            accuracy = accuracy,
            precision = precision,
            recall = recall,
            f1 = f1,
            kappa = kappa
        )
        models[[i]] <- model
    }
    
    return(list(models = models, results = results))
}

# Cross validation QDA
qda_cross_validate <- function(model_formula, data, k = 5) {
    set.seed(123) # Set seed for reproducibility
    
    # Create k-folds
    folds <- sample(rep(1:k, length.out = nrow(data)))
    
    # Initialize a list to store results and models
    results <- list()
    models <- list()
    
    # Perform cross-validation
    for (i in 1:k) {
        # Split data into training and testing sets
        train_data <- data[folds != i, ]
        test_data <- data[folds == i, ]
        
        # Train the model on the training set
        model <- qda(formula = model_formula, data = train_data)
        
        # Predict on the testing set
        predictions <- predict(model, test_data)$class
        
        # Calculate metrics
        confusion <- table(predictions, test_data$diabetes_012)
        accuracy <- sum(diag(confusion)) / sum(confusion)
        precision <- diag(confusion) / rowSums(confusion)
        precision[is.nan(precision)] <- 0
        recall <- diag(confusion) / colSums(confusion)
        recall[is.nan(recall)] <- 0
        f1 <- 2 * (precision * recall) / (precision + recall)
        f1[is.nan(f1)] <- 0
        
        # Convert confusion matrix to data frame for kappam.fleiss
        confusion_df <- as.data.frame(as.table(confusion))
        kappa <- kappam.fleiss(confusion_df)$value
        
        # Store the result and model
        results[[i]] <- list(
            accuracy = accuracy,
            precision = precision,
            recall = recall,
            f1 = f1,
            kappa = kappa
        )
        models[[i]] <- model
    }
    
    return(list(models = models, results = results))
}

eval_multi_class <- function(x) {
    cc <- sum(diag(x))
    sc <- sum(x)
    pp <- colSums(x)
    tt <- rowSums(x)
    ##
    prec <- diag(x)/colSums(x)
    recall <- diag(x)/rowSums(x)
    macro_prec <- mean(prec)
    macro_recall <- mean(recall)
    macro_f1 <- 2 * macro_prec * macro_recall/(1/macro_prec + 1/macro_recall)
    acc <- cc/sc
    kap <- (cc * sc - sum(pp * tt))/(sc^2 - sum(pp * tt))
    return(list(Precision = prec, Recall = recall, Accuracy = acc, Kappa = kap,
        Macro_F1 = macro_f1))
}

evaluate_models <- function(train_data, test_data) {
    # Apply cross-validation on train_data for LDA
    lda_results <- lda_cross_validate(diabetes_012 ~ ., train_data)
    lda_avg_results <- sapply(lda_results$results, function(res) sapply(res, mean))

    # Apply cross-validation on train_data for QDA
    qda_results <- qda_cross_validate(diabetes_012 ~ ., train_data)
    qda_avg_results <- sapply(qda_results$results, function(res) sapply(res, mean))

    # Combine results into a data frame
    avg_results <- data.frame(
        Metric = c("Accuracy", "Precision", "Recall", "F1", "Kappa"),
        LDA = lda_avg_results,
        QDA = qda_avg_results
    )

    # Print the results as a table
    print(avg_results)

    # Cross-validation on train_data for LDA
    lda_results <- lda_cross_validate(diabetes_012 ~ ., train_data)
    lda_avg_results <- sapply(lda_results$results, function(res) sapply(res, mean))
    
    # Cross-validation on train_data for QDA
    qda_results <- qda_cross_validate(diabetes_012 ~ ., train_data)
    qda_avg_results <- sapply(qda_results$results, function(res) sapply(res, mean))
    
    # Determine the best model based on average F1 score
    best_model <- ifelse(mean(lda_avg_results["f1", ]) > mean(qda_avg_results["f1", ]), "LDA", "QDA")
    
    # Train the best LDA model on the entire training data
    final_lda_model <- lda(diabetes_012 ~ ., data = train_data)
    
    # Train the best QDA model on the entire training data
    final_qda_model <- qda(diabetes_012 ~ ., data = train_data)
    
    # Predict on the test data using both models
    lda_predictions <- predict(final_lda_model, test_data)$class
    qda_predictions <- predict(final_qda_model, test_data)$class
    
    # Get predicted probabilities for both models
    lda_pred_probs <- predict(final_lda_model, test_data)$posterior
    qda_pred_probs <- predict(final_qda_model, test_data)$posterior
    
    # Create confusion matrices for both models
    lda_confusion <- table(test_data$diabetes_012, lda_predictions)
    qda_confusion <- table(test_data$diabetes_012, qda_predictions)
    
    # Calculate metrics for LDA using eval_multi_class
    lda_metrics <- eval_multi_class(lda_confusion)
    
    # Calculate metrics for QDA using eval_multi_class
    qda_metrics <- eval_multi_class(qda_confusion)
    
    # Create a data frame with the results
    results <- data.frame(
        Metric = c("Accuracy", "Precision", "Recall", "F1", "Kappa"),
        LDA = c(lda_metrics$Accuracy, mean(lda_metrics$Precision, na.rm = TRUE), mean(lda_metrics$Recall, na.rm = TRUE), lda_metrics$Macro_F1, lda_metrics$Kappa),
        QDA = c(qda_metrics$Accuracy, mean(qda_metrics$Precision, na.rm = TRUE), mean(qda_metrics$Recall, na.rm = TRUE), qda_metrics$Macro_F1, qda_metrics$Kappa)
    )
    
    # Plot the metrics
    metrics_data <- melt(results, id.vars = "Metric")
    
    ggplot(metrics_data, aes(x = Metric, y = value, fill = variable)) +
        geom_bar(stat = "identity", position = "dodge") +
        labs(title = "Performance Metrics for LDA and QDA Models",
             x = "Metric",
             y = "Value") +
        theme_minimal()
    
    # Return results, predicted probabilities, and predictions
    return(list(results = results, lda_pred_probs = lda_pred_probs, qda_pred_probs = qda_pred_probs, lda_predictions = lda_predictions, qda_predictions = qda_predictions))
}

plot_confusion_matrix <- function(conf_matrix, model_name) {
    conf_matrix_df <- as.data.frame(conf_matrix)
    colnames(conf_matrix_df) <- c("Actual", "Predicted", "Freq")
    
    ggplot(conf_matrix_df, aes(x = Actual, y = Predicted, fill = Freq)) +
        geom_tile() +
        geom_text(aes(label = Freq), color = "white") +
        scale_fill_gradient(low = "lightblue", high = "lightcoral") +
        labs(title = paste("Confusion Matrix -", model_name, "Predictions"), x = "Actual", y = "Predicted") +
        theme_minimal()
}
```


```{r}
train_data = read.csv("../data/train_data.csv")
test_data = read.csv("../data/test_data.csv")
```


```{r}
glimpse(train_data)
```


## Data Preprocessing


```{r}
train_data <- train_data |> mutate(across(everything(), as.factor))
test_data <- test_data |> mutate(across(everything(), as.factor))
```


```{r}
glimpse(train_data)
```


```{r}
print(table(train_data$diabetes_012))
print(table(test_data$diabetes_012))
```


## Modeling


Hàm Cross Validation với K Folds = 5 cho LDA và QDA


### Thử trên data gốc


```{r}
results = evaluate_models(train_data, test_data)
```


```{r}
conf_matrix <- table(test_data$diabetes_012, results$lda_predictions)
conf_matrix

eval_multi_class(conf_matrix)

plot_confusion_matrix(conf_matrix, "LDA")
```


```{r}
conf_matrix <- table(test_data$diabetes_012, results$qda_predictions)
conf_matrix

eval_multi_class(conf_matrix)
plot_confusion_matrix(conf_matrix, "QDA")
```


### Thử trên Data Oversampling


```{r}
oversampling_data <- read.csv("../data/oversampled_data.csv")
oversampling_data <- oversampling_data |> mutate(across(everything(), as.factor))

glimpse(oversampling_data)
```


```{r}
table(oversampling_data$diabetes_012)
```


#### Train với thông số cơ bản


```{r}
oversampling_results <- evaluate_models(oversampling_data, test_data)
```


```{r}
conf_matrix <- table(test_data$diabetes_012, oversampling_results$lda_predictions)
conf_matrix

eval_multi_class(conf_matrix)

# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "LDA")
```


```{r}
conf_matrix <- table(test_data$diabetes_012, oversampling_results$qda_predictions)
conf_matrix

eval_multi_class(conf_matrix)
# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "QDA")
```


#### Tăng Recall cho class 1 và class 2


```{r}
calculate_optimal_thresholds <- function(probs, test_data) {
    # Tính PR Curve cho từng lớp (One-vs-Rest)
    pr_class0 <- pr.curve(scores.class0 = probs[, 1], weights.class0 = (test_data$diabetes_012 == 0), curve = TRUE)
    pr_class1 <- pr.curve(scores.class0 = probs[, 2], weights.class0 = (test_data$diabetes_012 == 1), curve = TRUE)
    pr_class2 <- pr.curve(scores.class0 = probs[, 3], weights.class0 = (test_data$diabetes_012 == 2), curve = TRUE)

    # Vẽ đồ thị Precision-Recall
    plot(pr_class0, col = "blue", main = "PR Curve - Class 0")
    plot(pr_class1, col = "red", add = TRUE)
    plot(pr_class2, col = "green", add = TRUE)
    legend("bottomleft", legend = c("Class 0", "Class 1", "Class 2"), col = c("blue", "red", "green"), lty = 1)

    # Tính F1-Score cho từng lớp
    precision0 <- pr_class0$curve[, 1]
    recall0 <- pr_class0$curve[, 2]
    f1_class0 <- 2 * (precision0 * recall0) / (precision0 + recall0)
    optimal_threshold0 <- pr_class0$curve[which.max(f1_class0), 3]

    precision1 <- pr_class1$curve[, 1]
    recall1 <- pr_class1$curve[, 2]
    f1_class1 <- 2 * (precision1 * recall1) / (precision1 + recall1)
    optimal_threshold1 <- pr_class1$curve[which.max(f1_class1), 3]

    precision2 <- pr_class2$curve[, 1]
    recall2 <- pr_class2$curve[, 2]
    f1_class2 <- 2 * (precision2 * recall2) / (precision2 + recall2)
    optimal_threshold2 <- pr_class2$curve[which.max(f1_class2), 3]

    # In ngưỡng tối ưu
    optimal_threshold0
    optimal_threshold1
    optimal_threshold2

    # Đặt ngưỡng tối ưu
    thresholds <- c(optimal_threshold0, optimal_threshold1, optimal_threshold2)

    # Điều chỉnh xác suất dự đoán
    adjusted_probs <- probs
    adjusted_probs[, 1] <- ifelse(probs[, 1] > thresholds[1], probs[, 1], 0)
    adjusted_probs[, 2] <- ifelse(probs[, 2] > thresholds[2], probs[, 2], 0)
    adjusted_probs[, 3] <- ifelse(probs[, 3] > thresholds[3], probs[, 3], 0)

    # Phân loại dựa trên xác suất cao nhất
    predicted_class <- apply(adjusted_probs, 1, which.max) - 1

    return(list(optimal_thresholds = thresholds, predicted_class = predicted_class))
}
```


```{r}
lda_probs <- probs$lda_pred_probs
qda_probs <- probs$qda_pred_probs
```


Cho LDA


```{r}
result <- calculate_optimal_thresholds(lda_probs, test_data)
predicted_class <- result$predicted_class
optimal_thresholds <- result$optimal_thresholds

conf_matrix <- table(test_data$diabetes_012, predicted_class)
conf_matrix

eval_multi_class(conf_matrix)
# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "LDA-Threshold")
```


Cho QDA


```{r}
result <- calculate_optimal_thresholds(qda_probs, test_data)
predicted_class <- result$predicted_class
optimal_thresholds <- result$optimal_thresholds

conf_matrix <- table(test_data$diabetes_012, predicted_class)
conf_matrix

eval_multi_class(conf_matrix)
# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "QDA-Threshold")
```


### Thử trên Data Undersampling


```{r}
undersampling_data <- read.csv("../data/undersampled_data.csv")
undersampling_data <- undersampling_data |> mutate(across(everything(), as.factor))

glimpse(undersampling_data)

table(undersampling_data$diabetes_012)
```


#### Train với thông số cơ bản


```{r}
# Train LDA model on undersampling_data
lda_model <- lda(diabetes_012 ~ ., data = undersampling_data)

# Predict on undersampling_data
lda_predictions_train <- predict(lda_model, undersampling_data)$class
lda_pred_probs_train <- predict(lda_model, undersampling_data)$posterior

# Calculate confusion matrix and metrics for training data
lda_conf_matrix_train <- table(undersampling_data$diabetes_012, lda_predictions_train)
lda_metrics_train <- eval_multi_class(lda_conf_matrix_train)

# Print metrics for training data
cat("LDA Training Metrics:\n")
print(lda_metrics_train)

# Predict on test_data
lda_predictions <- predict(lda_model, test_data)$class
lda_pred_probs <- predict(lda_model, test_data)$posterior

# Train QDA model on undersampling_data
qda_model <- qda(diabetes_012 ~ ., data = undersampling_data)

# Predict on undersampling_data
qda_predictions_train <- predict(qda_model, undersampling_data)$class
qda_pred_probs_train <- predict(qda_model, undersampling_data)$posterior

# Calculate confusion matrix and metrics for training data
qda_conf_matrix_train <- table(undersampling_data$diabetes_012, qda_predictions_train)
qda_metrics_train <- eval_multi_class(qda_conf_matrix_train)

# Print metrics for training data
cat("QDA Training Metrics:\n")
print(qda_metrics_train)

# Predict on test_data
qda_predictions <- predict(qda_model, test_data)$class
qda_pred_probs <- predict(qda_model, test_data)$posterior

# Return predictions and probabilities for both models
undersampling_results <- list(
    lda_predictions = lda_predictions,
    lda_pred_probs = lda_pred_probs,
    qda_predictions = qda_predictions,
    qda_pred_probs = qda_pred_probs
)
```


Cho LDA


```{r}
conf_matrix <- table(test_data$diabetes_012, undersampling_results$lda_predictions)
conf_matrix

eval_multi_class(conf_matrix)

# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "LDA")
```


Cho QDA


```{r}
conf_matrix <- table(test_data$diabetes_012, undersampling_results$qda_predictions)
conf_matrix

eval_multi_class(conf_matrix)

# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "QDA")
```


### Thử trên Data SMOTE Sampling


```{r}
smote_data <- read.csv("../data/smote_augmented_data_80_percent.csv")
smote_data <- smote_data |> mutate(across(everything(), as.factor))

glimpse(smote_data)
table(smote_data$diabetes_012)
```


### Train với thông số cơ bản


```{r}
smote_results <- evaluate_models(smote_data, test_data)
```


```{r}
conf_matrix <- table(test_data$diabetes_012, smote_results$lda_predictions)
conf_matrix

eval_multi_class(conf_matrix)

# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "LDA")
```


```{r}
conf_matrix <- table(test_data$diabetes_012, smote_results$qda_predictions)
conf_matrix

eval_multi_class(conf_matrix)

# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "QDA")
```


## Modeling With Binary 0 & {1, 2}


```{r}
convert_to_binary <- function(data) {
    data |> mutate(diabetes_012 = ifelse(diabetes_012 %in% c(1, 2), 1, ifelse(diabetes_012 == 0, 0, diabetes_012)))
}


binary_train_data <- convert_to_binary(train_data)
binary_oversampling_data <- convert_to_binary(oversampling_data)
binary_undersampling_data <- convert_to_binary(undersampling_data)
binary_smote_data <- convert_to_binary(smote_data)
binary_test_data <- convert_to_binary(test_data)
```


```{r}
table(binary_train_data$diabetes_012)
table(binary_test_data$diabetes_012)
```


### Train Data


```{r}
binary_results <- evaluate_models(binary_train_data, binary_test_data)
```


Cho LDA


```{r}
conf_matrix <- table(binary_test_data$diabetes_012, binary_results$lda_predictions)
conf_matrix

eval_multi_class(conf_matrix)

# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "LDA")
```


Cho QDA


```{r}
conf_matrix <- table(binary_test_data$diabetes_012, binary_results$qda_predictions)
conf_matrix

eval_multi_class(conf_matrix)

# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "QDA")
```


### Oversampling Data


```{r}
oversampling_results_binary <- evaluate_models(binary_oversampling_data, binary_test_data)
```


Cho LDA


```{r}
conf_matrix <- table(binary_test_data$diabetes_012, oversampling_results_binary$lda_predictions)
conf_matrix

eval_multi_class(conf_matrix)

# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "LDA")
```


Cho QDA


```{r}
conf_matrix <- table(binary_test_data$diabetes_012, oversampling_results_binary$qda_predictions)
conf_matrix

eval_multi_class(conf_matrix)

# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "QDA")
```


### Undersampling Data


```{r}
undersampling_results_binary <- evaluate_models(binary_undersampling_data, binary_test_data)
```


Cho LDA


```{r}
conf_matrix <- table(binary_test_data$diabetes_012, undersampling_results_binary$lda_predictions)
conf_matrix

eval_multi_class(conf_matrix)

# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "LDA")
```


Cho QDA


```{r}
conf_matrix <- table(binary_test_data$diabetes_012, undersampling_results_binary$qda_predictions)
conf_matrix

eval_multi_class(conf_matrix)

# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "QDA")
```


### SMOTE Data


```{r}
smote_results_binary <- evaluate_models(binary_undersampling_data, binary_test_data)
```


Cho LDA


```{r}
conf_matrix <- table(binary_test_data$diabetes_012, smote_results_binary$lda_predictions)
conf_matrix

eval_multi_class(conf_matrix)

# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "LDA")
```


Cho QDA


```{r}
conf_matrix <- table(binary_test_data$diabetes_012, smote_results_binary$qda_predictions)
conf_matrix

eval_multi_class(conf_matrix)

# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "QDA")
```

## Modeling with Binary 1 & {0, 2}

Class 0 và 2 sẽ được biến đổi thành class 1 và class 1 sẽ được chỉnh thành 0.

```{r}
convert_to_binary <- function(data) {
    data |> mutate(diabetes_012 = ifelse(diabetes_012 %in% c(0, 2), 1, ifelse(diabetes_012 == 1, 0, diabetes_012)))
}

binary_train_data <- convert_to_binary(train_data)
binary_oversampling_data <- convert_to_binary(oversampling_data)
binary_undersampling_data <- convert_to_binary(undersampling_data)
binary_smote_data <- convert_to_binary(smote_data)
binary_test_data <- convert_to_binary(test_data)
```


```{r}
table(binary_train_data$diabetes_012)
table(binary_test_data$diabetes_012)
```


### Train Data


```{r}
binary_results <- evaluate_models(binary_train_data, binary_test_data)
```


Cho LDA


```{r}
conf_matrix <- table(binary_test_data$diabetes_012, binary_results$lda_predictions)
conf_matrix

eval_multi_class(conf_matrix)

# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "LDA")
```


Cho QDA


```{r}
conf_matrix <- table(binary_test_data$diabetes_012, binary_results$qda_predictions)
conf_matrix

eval_multi_class(conf_matrix)

# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "QDA")
```


### Oversampling Data


```{r}
oversampling_results_binary <- evaluate_models(binary_oversampling_data, binary_test_data)
```


Cho LDA


```{r}
conf_matrix <- table(binary_test_data$diabetes_012, oversampling_results_binary$lda_predictions)
conf_matrix

eval_multi_class(conf_matrix)

# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "LDA")
```


Cho QDA


```{r}
conf_matrix <- table(binary_test_data$diabetes_012, oversampling_results_binary$qda_predictions)
conf_matrix

eval_multi_class(conf_matrix)

# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "QDA")
```


### Undersampling Data


```{r}
undersampling_results_binary <- evaluate_models(binary_undersampling_data, binary_test_data)
```


Cho LDA


```{r}
conf_matrix <- table(binary_test_data$diabetes_012, undersampling_results_binary$lda_predictions)
conf_matrix

eval_multi_class(conf_matrix)

# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "LDA")
```


Cho QDA


```{r}
conf_matrix <- table(binary_test_data$diabetes_012, undersampling_results_binary$qda_predictions)
conf_matrix

eval_multi_class(conf_matrix)

# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "QDA")
```


### SMOTE Data


```{r}
smote_results_binary <- evaluate_models(binary_undersampling_data, binary_test_data)
```


Cho LDA


```{r}
conf_matrix <- table(binary_test_data$diabetes_012, smote_results_binary$lda_predictions)
conf_matrix

eval_multi_class(conf_matrix)

# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "LDA")
```


Cho QDA


```{r}
conf_matrix <- table(binary_test_data$diabetes_012, smote_results_binary$qda_predictions)
conf_matrix

eval_multi_class(conf_matrix)

# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "QDA")
```

## Modeling with Binary 2 & {0, 1}

Class 0 và 1 biến đổi thành class 1 và class 2 được biến đổi thành class 1

```{r}
convert_to_binary <- function(data) {
    data |> mutate(diabetes_012 = ifelse(diabetes_012 %in% c(0, 1), 0, ifelse(diabetes_012 == 2, 1, diabetes_012)))
}

binary_train_data <- convert_to_binary(train_data)
binary_oversampling_data <- convert_to_binary(oversampling_data)
binary_undersampling_data <- convert_to_binary(undersampling_data)
binary_smote_data <- convert_to_binary(smote_data)
binary_test_data <- convert_to_binary(test_data)
```


```{r}
table(binary_train_data$diabetes_012)
table(binary_test_data$diabetes_012)
```


### Train Data


```{r}
binary_results <- evaluate_models(binary_train_data, binary_test_data)
```


Cho LDA


```{r}
conf_matrix <- table(binary_test_data$diabetes_012, binary_results$lda_predictions)
conf_matrix

eval_multi_class(conf_matrix)

# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "LDA")
```


Cho QDA


```{r}
conf_matrix <- table(binary_test_data$diabetes_012, binary_results$qda_predictions)
conf_matrix

eval_multi_class(conf_matrix)

# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "QDA")
```


### Oversampling Data


```{r}
oversampling_results_binary <- evaluate_models(binary_oversampling_data, binary_test_data)
```


Cho LDA


```{r}
conf_matrix <- table(binary_test_data$diabetes_012, oversampling_results_binary$lda_predictions)
conf_matrix

eval_multi_class(conf_matrix)

# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "LDA")
```


Cho QDA


```{r}
conf_matrix <- table(binary_test_data$diabetes_012, oversampling_results_binary$qda_predictions)
conf_matrix

eval_multi_class(conf_matrix)

# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "QDA")
```


### Undersampling Data


```{r}
undersampling_results_binary <- evaluate_models(binary_undersampling_data, binary_test_data)
```


Cho LDA


```{r}
conf_matrix <- table(binary_test_data$diabetes_012, undersampling_results_binary$lda_predictions)
conf_matrix

eval_multi_class(conf_matrix)

# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "LDA")
```


Cho QDA


```{r}
conf_matrix <- table(binary_test_data$diabetes_012, undersampling_results_binary$qda_predictions)
conf_matrix

eval_multi_class(conf_matrix)

# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "QDA")
```


### SMOTE Data


```{r}
smote_results_binary <- evaluate_models(binary_undersampling_data, binary_test_data)
```


Cho LDA


```{r}
conf_matrix <- table(binary_test_data$diabetes_012, smote_results_binary$lda_predictions)
conf_matrix

eval_multi_class(conf_matrix)

# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "LDA")
```


Cho QDA


```{r}
conf_matrix <- table(binary_test_data$diabetes_012, smote_results_binary$qda_predictions)
conf_matrix

eval_multi_class(conf_matrix)

# Plot confusion matrix using the function
plot_confusion_matrix(conf_matrix, "QDA")
```





